{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dieko95/blackouts-C4V/blob/diego-first-iter/twitter_pretagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYeFRTD02JJd"
   },
   "source": [
    "# Training Dataset Creation - Tagging \n",
    "\n",
    "This notebook aims to create the dataset for Code for Venezuela's Blackout Project. \n",
    "\n",
    "This dataset is going to be consumed by an ML model that will aim to predict: \n",
    "\n",
    "- If a tweet is from Venezuela\n",
    "- If so from which state(s) \n",
    "- About what public service the user is reporting (sinluz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rPjvaTP1pN6_"
   },
   "source": [
    "## Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YESX9HG2pMWC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# For better visualization of text in Pandas DF\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(df,text_col, is_pandas_series = False):\n",
    "    '''\n",
    "    Helper function to do basic text cleaning operations. \n",
    "    These include: Converting text to lower case, removing spanish accents,and removing links.\n",
    "    -------------------------------------------------------------------------------------------\n",
    "    PARAMS\n",
    "        df: Dataframe or Pandas.Series object. \n",
    "        text_col: String. Column to clean. \n",
    "        is_pandas_series: Boolean, Optional. If df is pandas.Series\n",
    "    \n",
    "    '''\n",
    "    \n",
    "  # to lower\n",
    "\n",
    "    if is_pandas_series == False:\n",
    "        df[text_col] = df[text_col].str.lower()\n",
    "\n",
    "      # Convert common spanish accents\n",
    "\n",
    "        df[text_col] = df[text_col].str.replace(\"Ãº\", \"u\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã¹\", \"u\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã¼\", \"u\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã³\", \"o\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã²\", \"o\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã­\", \"i\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã¬\", \"i\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã©\", \"e\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã¨\", \"e\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã¡\", \"a\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã \", \"a\")\n",
    "        df[text_col] = df[text_col].str.replace(\"Ã±\", \"gn\")\n",
    "\n",
    "        # Remove Punctuation\n",
    "        df[text_col] = df[text_col].str.replace(\"[\\.\\-:,]\", \" \")\n",
    "\n",
    "        # Remove links\n",
    "        df[text_col] = df[text_col].str.replace(\"http.+\", \" \")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    elif is_pandas_series == True:\n",
    "        \n",
    "        df = df.str.lower()\n",
    "\n",
    "      # Convert common spanish accents\n",
    "\n",
    "        df = df.str.replace(\"Ãº\", \"u\")\n",
    "        df = df.str.replace(\"Ã¹\", \"u\")\n",
    "        df = df.str.replace(\"Ã¼\", \"u\")\n",
    "        df = df.str.replace(\"Ã³\", \"o\")\n",
    "        df = df.str.replace(\"Ã²\", \"o\")\n",
    "        df = df.str.replace(\"Ã­\", \"i\")\n",
    "        df = df.str.replace(\"Ã¬\", \"i\")\n",
    "        df = df.str.replace(\"Ã©\", \"e\")\n",
    "        df = df.str.replace(\"Ã¨\", \"e\")\n",
    "        df = df.str.replace(\"Ã¡\", \"a\")\n",
    "        df = df.str.replace(\"Ã \", \"a\")\n",
    "        df = df.str.replace(\"Ã±\", \"gn\")\n",
    "\n",
    "        # Remove Punctuation\n",
    "        df = df.str.replace(\"[\\.\\-:,]\", \" \")\n",
    "\n",
    "        # Remove links\n",
    "        df = df.str.replace(\"http.+\", \" \")\n",
    "        \n",
    "        return df\n",
    "\n",
    "def text_matcher(text,list_to_compare,is_pd_series = False):\n",
    "    if is_pd_series == False:\n",
    "     \n",
    "        for i in list_to_compare:\n",
    "            if i in text:\n",
    "                print(i)\n",
    "            else:\n",
    "                next\n",
    "    \n",
    "    \n",
    "    elif is_pd_series == True:\n",
    "        \n",
    "        text = cleaner(pd.DataFrame({'col':[tst]}), 'col').to_string()\n",
    "\n",
    "        for i in list_to_compare:\n",
    "            if i in text:\n",
    "                print(i)\n",
    "            else:\n",
    "                next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tUGVhRHs5OZn"
   },
   "source": [
    "## Accessing Data\n",
    "\n",
    "The untagged dataset originates from scraped tweets by Code For Venezuela's Angostura ETL. A subset of tweets (11,000) was queried from the etl in order for them to be tagged. The first 4,000 tweets have already been tagged. \n",
    "\n",
    "- 6578 Tweets without tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rN37zlHcfbj0"
   },
   "outputs": [],
   "source": [
    "# Read CSV from github \n",
    "# tagOriginalDf = pd.read_csv('https://raw.githubusercontent.com/dieko95/blackouts-C4V/diego-first-iter/tagging-set-original_for_jupyter_tagging.csv')\n",
    "tagOriginalDf = pd.read_csv('tagging-set-original_for_jupyter_tagging.csv')\n",
    "\n",
    "tagOriginalDf.label_country.fillna('0', inplace = True)\n",
    "tagOriginalDf = cleaner(tagOriginalDf, 'label_country')\n",
    "\n",
    "# Corresponding Section\n",
    "# tags_df = tagOriginalDf.iloc[6001:8499,:].copy()\n",
    "tags_df = tagOriginalDf.iloc[:,:].copy()\n",
    "\n",
    "# Tagged Tweets\n",
    "pre_tag_df = tags_df.loc[tags_df.label_country != '0',['full_text','concat_text_user_description', 'label_country', 'label_state', 'label_type']].copy()\n",
    "pre_tag_df['label_country'] = pre_tag_df.label_country.str.replace('espa\\w+','espagna')\n",
    "pre_tag_df['label_country'] = pre_tag_df.label_country.str.replace('arg\\w+','argentina')\n",
    "\n",
    "\n",
    "# Tweets to tag\n",
    "to_tag_df = tags_df.loc[tags_df.label_country == '0',['full_text','concat_text_user_description', 'label_country', 'label_state', 'label_type']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aROWrNLK52aq"
   },
   "source": [
    "## Cleaning Text\n",
    "\n",
    "This is a helper function to quickly clean text.\n",
    "\n",
    "- Converts all text to low caps. \n",
    "- Strips all spanish accents\n",
    "\n",
    "Pending:\n",
    "\n",
    "- Strip dots and links (@ and # must remain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ec-4OIX6BAi"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pre_tag_df = cleaner(pre_tag_df, 'full_text')\n",
    "to_tag_df = cleaner(to_tag_df, 'concat_text_user_description')\n",
    "to_tag_df = cleaner(to_tag_df, 'full_text')\n",
    "\n",
    "\n",
    "# 3546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtogO9m3jv2n"
   },
   "source": [
    "## Sections to Tag \n",
    "\n",
    "- Tag label_type (service reported)\n",
    "  - Extracting pound signs (\\#)\n",
    "\n",
    "- Tag Country\n",
    "  - Matches any state? \n",
    "  - has keyword 'edo' or 'estado' in it?\n",
    "  - Follows any of the common accounts?\n",
    "- Tag State\n",
    "  - Match with list of venezuela states\n",
    "  - We can use a list of venezuelan cities as well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJQo6Q725duV"
   },
   "source": [
    "### Classifying Label Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEVa39Xe5ogc"
   },
   "source": [
    "#### Hashtags\n",
    "\n",
    "* \\#SinLuz\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOMhF-6eCFxY"
   },
   "outputs": [],
   "source": [
    "\n",
    "# sinluz         670\n",
    "# ahora           68\n",
    "# sinagua         66\n",
    "# apagon          65\n",
    "# singasolina     53\n",
    "\n",
    "hashtags = pd.Series(re.findall('#(\\w+)', to_tag_df.concat_text_user_description.to_string())).copy()\n",
    "\n",
    "# hashtags.value_counts()[hashtags.value_counts() > 10]\n",
    "\n",
    "# hashtags[hashtags == 'sinl']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clJfc4I_vpdH"
   },
   "source": [
    "### Tagging Country\n",
    "\n",
    "  - Matches any state? \n",
    "  - has keyword 'edo' or 'estado' in it?\n",
    "  - Follows any of the common accounts?\n",
    "\n",
    "*Notes*\n",
    "  - For this section I will use the tweet's original text. If I include the user description it can add noise because a user can be reporting about a power outage of another state (e.g., I'm from caracas and reporting a power outage in Zulia)\n",
    "  \n",
    " - Menciones a cuentas: \n",
    "\n",
    "Generales\n",
    "\n",
    "- @NicolsMaduro\n",
    "- @DanteRivasQ\n",
    "- @ReporteYa\n",
    "- @Gob_Vargas\n",
    "- @ReporteYa\n",
    "- @FBritoMaestre\n",
    "- @efectococuyo\n",
    "\n",
    "\n",
    "Electricidad\n",
    "\n",
    "- @CORPOELECinfo\n",
    "- @CORPOELECgua_\n",
    "- @corpoelecmerida\n",
    "- @MPPAAguas\n",
    "- @CorpoelecCar\n",
    "- @ClimaMargarita\n",
    "\n",
    "Agua \n",
    "- @hidrovenca\n",
    "- @hidrocapitalca\n",
    "- @MPPAAguas\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging non-venezuelan countries\n",
    "\n",
    "<br>\n",
    "\n",
    "- Before this subsection: 6,578 non-tagged Tweets\n",
    "- After this subsection: \n",
    "\n",
    "###### New labeled countries  \n",
    "\n",
    "<br>\n",
    "\n",
    "These are the results after grouping non-venezuelan accounts and tagging accordingly\n",
    "\n",
    "<br>\n",
    "\n",
    "|     label_country    \t| frequency \t|\n",
    "|:--------------------:\t|:---------:\t|\n",
    "|           0          \t|    6112   \t|\n",
    "|       argentina      \t|    410    \t|\n",
    "|        mexico        \t|     25    \t|\n",
    "|       not sure       \t|     24    \t|\n",
    "| republica domenicana \t|     7     \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "###### Notes:\n",
    "\n",
    "- Most common accounts in non-venezuelan tweets\n",
    "\n",
    "<br>\n",
    "\n",
    "|     Account    \t| total frequency \t|\n",
    "|:--------------:\t|:---------------:\t|\n",
    "|  oficialedesur \t|       340       \t|\n",
    "| edenorclientes \t|       180       \t|\n",
    "|    se_corto    \t|        15       \t|\n",
    "| cortes_en_bsas \t|        13       \t|\n",
    "|    alferdez    \t|        9        \t|\n",
    "|  todonoticias  \t|        6        \t|\n",
    "|  mauriciomacri \t|        6        \t|\n",
    "|    enre_arg    \t|        6        \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list containing tagged countries except venezuela\n",
    "non_venezuela_tags = pre_tag_df.label_country[pre_tag_df.label_country != 'venezuela'].value_counts().index.tolist()\n",
    "\n",
    "\n",
    "# Each element of non venezuelan tags (e.g. Argentina, Republica Domenicana, etc...)\n",
    "for element in non_venezuela_tags:\n",
    "    \n",
    "     # Loop over pre-tagged dataframe\n",
    "    # Find all @ with at least 3 characters after the @\n",
    "    common_users = '|'.join(re.findall('@(\\w{3,})', # Find all users (characters that begin with a @)\n",
    "                         pre_tag_df.loc[pre_tag_df.label_country == element,'full_text'].to_string()))\n",
    "    \n",
    "    # If the tweet does not have mentions skip to the next\n",
    "    if common_users == '':\n",
    "    \n",
    "        next\n",
    "    \n",
    "   # If the tweets have mentions detect which have those mentions\n",
    "    elif common_users != '':\n",
    "        \n",
    "        # loop over untagged dataframe\n",
    "        for index, value in to_tag_df['full_text'].iteritems():\n",
    "            \n",
    "            # Create re object with common users patterns (e.g. 'edesur|macri' etc...)\n",
    "            regexp = re.compile(common_users)\n",
    "            \n",
    "            # If there is a user in the tweet\n",
    "            if regexp.search(value):\n",
    "                \n",
    "                # Replace the tweet's label_country to the country of the loop\n",
    "                to_tag_df.loc[index,'label_country'] = element\n",
    "            \n",
    "            else:\n",
    "                next\n",
    "    \n",
    "    # Simple error handling, be careful of morgoth's bugs!\n",
    "    else:\n",
    "        print('Morgoth has introduced an error!')\n",
    "\n",
    "\n",
    "\n",
    "### SANITY CHECK SECTION \n",
    "# re.findall('@(\\w{3,})', # Find all users (characters that begin with a @)\n",
    "#                          pre_tag_df.loc[pre_tag_df.label_country == 'not sure','full_text'].to_string())\n",
    "\n",
    "\n",
    "# to_tag_df.loc[to_tag_df.label_country == '0','full_text'].str.contains('argentina').sum()\n",
    "\n",
    "# pre_tag_df.loc[pre_tag_df.label_country == 'not sure','full_text'].str.contains('edesur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging countries that aren't Venezuela\n",
    "\n",
    "<br>\n",
    "\n",
    "- Frequently when venezuelan users refer to other countries they are not reporting a specific public service problem in Venezuela. \n",
    "\n",
    "\n",
    "| index \t| Text and User Description                                                                                                                                                                                                                                       \t|\n",
    "|-------\t|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| 4540  \t| el pais #singasolina por culpa de un gobierno ineficiente  inepto y corrupto que prefiere <br> seguir subsidiando a las mafias para que estas sigan desangrando al pais <br> llevandose la gasolina a colombia  el pais esta #singasolina por falta de gobierno \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "| index \t| Text and User Description                                                                                                                                                                                                                                                                                                                                                                                                                         \t|\n",
    "|-------\t|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| 5417  \t| #singasolina \\n @earisteguieta  \"no hay gasolina suficiente para nuestro consumo dejamos de producirla y <br> no hay dinero para comprar asi termina el aÃ±o y comenzara el proximo pero para cuba si hay <br> y gratis nos toca decidir si seguimos aceptando esto o nos hacemos respetar\" <br> \"sala de informacion\" \"saladeinfo\" \"agencia de noticias y comunicaciones integradas  productora de contenidos informativos  de opinion y analisis \t|\n",
    "\n",
    "\n",
    "<br> \n",
    "\n",
    "**Exceptions**\n",
    "\n",
    "1.  When streets are named as foreign countries (e.g. Avenida Mexico) or places named as foreign countries (see below).\n",
    "\n",
    "<br>\n",
    "\n",
    "| index \t| Text and User Description                                                                                                                                         \t|\n",
    "|-------\t|-------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| 4215  \t| #22nov #guayana alta vista  los olivos  castillito  ***villa colombia***  villa asia  villa alianza  ***villa brasil*** #sinluz \"leonervis\" \"leonervis\" \"periodistaðŸ“° locutora \t|\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "2. When users report a public service problem and also complain \n",
    "\n",
    "| index \t| Text and User Description                                                                                                                                                                                                       \t|\n",
    "|-------\t|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| 5481  \t|  #sinluz valencia el parral desde las 6 00 p m   pero tenemos dialogo en barbados que maravilla!!! \"mario carrera\" \"1elprimero\" \"la unica cosa necesaria para que triunfe el mal   es que los hombres de bien no hagamos nada \" \t|\n",
    "\n",
    "<br>\n",
    "\n",
    "###### Notes:\n",
    "\n",
    "<br>\n",
    "\n",
    "This type of tweet is nearly impossible to tag. There's no information about municipality, state, nor country. \n",
    "\n",
    "<br> \n",
    "\n",
    "| index \t| Text and User Description                                                                                                    \t|\n",
    "|-------\t|------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| 5610  \t| #sinluz terrazas del club hipico   calle bolivia ðŸ˜­ \"dani medina\" \"dampita02\" \"me dicen dampita  y me gustan los aguacates ðŸ¥‘\"|\n",
    "\n",
    "\n",
    "<br> \n",
    "\n",
    "Tweets with the venezuelan flag not necessarily refer to power outages. Probably using venezuela or ðŸ‡»ðŸ‡ª is too general and can capture more noise than signal.  \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "| index \t| Text and User Description                                                                   \t|\n",
    "|-------\t|---------------------------------------------------------------------------------------------\t|\n",
    "| 6357  \t| ahora en https://t.co/h1paJ2DKHa \\ntambien podras jugar desde chile las carreras de ðŸ‡»ðŸ‡ª y cobrar en pesos chilenos!   |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read countries csv \n",
    "countries = pd.read_csv('countries.csv', \n",
    "                       squeeze = True) # Squeeze parses the csv as a pd.Series\n",
    "countries = cleaner(countries,\n",
    "        text_col=None,\n",
    "        is_pandas_series=True)\n",
    "\n",
    "# countries = countries.to_list()\n",
    "# countries[0] = f'\\s{countries[0]}'\n",
    "# countries[-1] = f'{countries[-1]}\\s'\n",
    "\n",
    "regexp = re.compile(common_users)\n",
    "\n",
    "for index, value in to_tag_df.loc[to_tag_df.label_country == '0','full_text'].iteritems():\n",
    "    for country in countries:\n",
    "#         if country in value:\n",
    "        regexp = re.compile(f'\\s{country}\\s')\n",
    "    \n",
    "        if regexp.search(value):\n",
    "#             print(country, index) # Sanity Check\n",
    "            to_tag_df.loc[index,'label_country'] = country\n",
    "        elif not regexp.search(value):\n",
    "#             print('NOPE')\n",
    "            next\n",
    "        else:\n",
    "            print('Melkor robbed the silmarils and left a bug! Contact the owner of the notebook')\n",
    "\n",
    "to_tag_df.loc[[6649,4215,7567,5529,7714,7967,10191,5481,5610,6533,7628], 'label_country'] = 'venezuela'\n",
    "\n",
    "\n",
    "# 4540, 8824 # General Complaint They are tagged as Colombia, I'm gonna leave them like that. \n",
    "\n",
    "# To Others\n",
    "# Cuba \n",
    "# Colombia\n",
    "# rusia\n",
    "# libia\n",
    "# ecuador\n",
    "# To Argentina\n",
    "# Mauricio \n",
    "# brasil\n",
    "\n",
    "## Sanity check \n",
    "\n",
    "# to_tag_df.label_country.value_counts()\n",
    "### RESULTS\n",
    "# # 0                       5992\n",
    "# argentina                406\n",
    "# mexico                    26\n",
    "# uruguay                   25\n",
    "# not sure                  24\n",
    "# chile                     13\n",
    "# venezuela                 11\n",
    "# colombia                  10\n",
    "# mauricio                   7\n",
    "# republica domenicana       7\n",
    "# paraguay                   6\n",
    "# cuba                       6\n",
    "# rusia                      6\n",
    "# china                      5\n",
    "# israel                     4\n",
    "# suiza                      4\n",
    "# peru                       3\n",
    "# italia                     3\n",
    "# canada                     2\n",
    "# espagna                    2\n",
    "# angola                     2\n",
    "# paises bajos               1\n",
    "# belice                     1\n",
    "# honduras                   1\n",
    "# reino unido                1\n",
    "# japon                      1\n",
    "# ecuador                    1\n",
    "# libia                      1\n",
    "# iran                       1\n",
    "# nicaragua                  1\n",
    "# bolivia                    1\n",
    "# egipto                     1\n",
    "# barbados                   1\n",
    "# zimbabue                   1\n",
    "# brasil                     1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "LXRzNfuXGk-G",
    "outputId": "736e7a70-5b35-4889-f463-45522fed64e6"
   },
   "outputs": [],
   "source": [
    "# Read csv with Venezuela's administrative distribution\n",
    "geo_df = pd.read_excel('../cod.xlsx')\n",
    "geo_df.fillna('NULL',\n",
    "              inplace = True)\n",
    "\n",
    "\n",
    "# Clean Columns\n",
    "cols = ['parroquia', 'nombrepob', 'estado','nom_mun']\n",
    "\n",
    "for col in cols:\n",
    "  geo_df = cleaner(geo_df, col)\n",
    "\n",
    "# # Unique pob name\n",
    "#   # CHECK ENCODING ERROR WITH JESUS  carupano\n",
    "# # geo_df.nombrepob.unique()\n",
    "\n",
    "\n",
    "\n",
    "# Which indices contain any state \n",
    "indices = to_tag_df.full_text.str.contains('|'.join(state), \n",
    "                                              case = False) # 6754\n",
    "\n",
    "def countryTagger(dataframe,text_column,target_column=None):\n",
    "    \n",
    "        # Read states\n",
    "    state = geo_df.estado.unique().tolist() # 612 tagged only with state\n",
    "\n",
    "    # Read Municipalities\n",
    "    muni = geo_df.nom_mun.unique().tolist() \n",
    "\n",
    "    # Read population names\n",
    "    pob_name = geo_df.nombrepob.unique().tolist() \n",
    "\n",
    "    # Read parish names\n",
    "    parish = geo_df.parroquia.unique().tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    common_vzla_accounts = [\"@NicolsMaduro\",\"@DanteRivasQ\",\n",
    "                            \"@ReporteYa\",\"@Gob_Vargas\",\n",
    "                            \"@ReporteYa\",\"@FBritoMaestre\",\n",
    "                            \"@CORPOELECinfo\",\"@CORPOELECgua_\",\n",
    "                            \"@corpoelecmerida\",\"@MPPAAguas\",\n",
    "                            \"@CorpoelecCar\",\"@ClimaMargarita\",\n",
    "                            \"@hidrovenca\",\"@hidrocapitalca\",\n",
    "                            \"@MPPAAguas, @efectococuyo\"\n",
    "                           ]\n",
    "    \n",
    "    all_tokens = state + common_vzla_accounts\n",
    "    \n",
    "\n",
    "    \n",
    "#     not_vzla = f'[^{\"|\".join(countries)}]'\n",
    "    \n",
    "    \n",
    "    vzla_locations = '\\s|\\s'.join(set(all_tokens))  #+ \n",
    "    \n",
    "    _indices = dataframe[text_column].str.contains(vzla_locations, \n",
    "                                                      case = False)\n",
    "    \n",
    "    return _indices \n",
    "\n",
    "# Testing\n",
    "######################################\n",
    "# idx=countryTagger(to_tag_df, 'full_text')\n",
    "# idx2 = to_tag_df.loc[idx,'full_text'].str.contains('edesur').tolist()\n",
    "\n",
    "# to_tag_df.loc[idx,'full_text'][idx2]\n",
    "\n",
    "# Which indices contain any municipality\n",
    "# indices = to_tag_df.full_text.str.contains('|'.join(set(muni)), \n",
    "#                                               case = False)\n",
    "###########################3\n",
    "\n",
    "# Which indices contain \"edo\"\n",
    "# indices = to_tag_df.full_text.str.contains('\\sedo', case = False)\n",
    "\n",
    "## View results\n",
    "# to_tag_df[indices]\n",
    "\n",
    "## Tag Venezuela \n",
    "# to_tag_df.loc[indices,'label_country'] = 'venezuela'\n",
    "\n",
    "\n",
    "\n",
    "## Quality Control \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # If there's more than one element in state then it's multiple\n",
    "\n",
    "\n",
    "text_matcher('ACTUALIZADO: Usuarios sin suministro elÃ©ctrico: @OficialEdesur @EdenorClientes #SinLuz #SeCorto https://t.co/jSuw4Lz0ng',non_venezuela_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fjSzeAw-8n_p"
   },
   "source": [
    "#### Municipality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qF_-hJy-8cvm"
   },
   "outputs": [],
   "source": [
    "\n",
    "## There's a municipality calledfull_text\n",
    "  # Democracy \n",
    "\n",
    "# indices = to_tag_df.concat_text_user_description.str.contains('|'.join(muni), case = False) # 6754\n",
    "\n",
    "# to_tag_df[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "colab_type": "code",
    "id": "59pCEiIMjYuQ",
    "outputId": "1769f705-e4f5-4969-adc9-eb3e546c103e"
   },
   "outputs": [],
   "source": [
    "# 653 tweets with hashtags Out of 2228 tweets\n",
    "\n",
    "\n",
    "\n",
    "indices = to_tag_df.concat_text_user_description.str.contains('venezuela', case = False) # 6754\n",
    "\n",
    "to_tag_df[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMZGyQZR0cmE"
   },
   "source": [
    "## Tagging State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sEMAHvA3ToW"
   },
   "source": [
    "\n",
    "Incluimos cuentas que reportan a nivel nacional? Es ruido porque lo que hacen es repetir lo que otros usuarios dicen? O captura seÃ±al porque son reportes de fallas de luz?\n",
    "\n",
    "~~~\n",
    "print(tags_df.loc[8122,'full_text'])\n",
    "\n",
    "#Ahora Reportan mÃ¡s zonas #SinLuz: \n",
    "\n",
    "Catia, Distrito Capital âŒðŸ’¡\n",
    "Guatire y Guarenas, Edo. Miranda âŒðŸ’¡\n",
    "Estado MÃ©rida âŒðŸ’¡\n",
    "Estado Aragua âŒðŸ’¡\n",
    "\n",
    "Comenta si hay fallas en tu zona #2Oct\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "colab_type": "code",
    "id": "-b9rpo0XsdiY",
    "outputId": "0e4f2416-a452-4048-ed08-60813b8f5d2b"
   },
   "outputs": [],
   "source": [
    "\n",
    "_multiple = []\n",
    "_single = []\n",
    "for index,row in to_tag_df.loc[to_tag_df.label_country == 'venezuela', 'full_text'].iteritems():\n",
    "  _lst = []\n",
    "\n",
    "  for state_name in state:\n",
    "\n",
    "    if state_name in row:\n",
    "      _lst.append(1)\n",
    "    \n",
    "\n",
    "      if len(_lst) == 1:\n",
    "        _single.append(index)\n",
    "\n",
    "      elif len(_lst) > 1:\n",
    "        _multiple.append(index)\n",
    "\n",
    "      else:\n",
    "        next\n",
    "\n",
    "\n",
    "      print(len(_lst), '------', index)\n",
    "    else:\n",
    "      next\n",
    "\n",
    "print(_single)\n",
    "\n",
    "# tst = to_tag_df.loc[8122,'full_text']\n",
    "# tst = cleaner(pd.DataFrame({'col':[tst]}), 'col').to_string()\n",
    "# # If there's more than one element in state then it's multiple\n",
    "# for i in state:\n",
    "#   if i in tst:\n",
    "#     print(i)\n",
    "#   else:\n",
    "#     next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize \n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "\n",
    "# import nltk \n",
    "# nltk.download('punkt')\n",
    "\n",
    "bigram = []\n",
    "\n",
    "for index,row in to_tag_df.loc[to_tag_df.label_country == 'venezuela', 'full_text'].iteritems():\n",
    "     \n",
    "    token = nltk.word_tokenize(row)\n",
    "    bigram.append( list(ngrams(token, 3)) )\n",
    "\n",
    "#     print(index)\n",
    "#     print(bigram)\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_tag_df.loc[6378,'full_text']\n",
    "\n",
    "bigram_dict = dict(zip(to_tag_df.loc[to_tag_df.label_country == 'venezuela', 'full_text'].index.tolist(), bigram))\n",
    "\n",
    "for k,v in bigram_dict.items():\n",
    "    for token in v: \n",
    "        if 'municipio' in token and 'miranda' in token:\n",
    "#             print(k,v)\n",
    "            print(token)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPt2UO62phN/lGX0RczE94E",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "twitter-pretagging",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
